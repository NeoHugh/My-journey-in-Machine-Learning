{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54256, 510)\n",
      "(54256,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "\n",
    "Xtrain_path='./data/X_train.csv'\n",
    "Ytrain_path='./data/Y_train.csv'\n",
    "with open (Xtrain_path,encoding='utf8') as f:\n",
    "    next (f)\n",
    "    X= np.array([ each.strip('/n').split(',')[1:] for each in f],dtype=float)\n",
    "with open(Ytrain_path,encoding='utf8') as f:\n",
    "    next(f)\n",
    "    Y= np.array([each.strip('\\n').split(',')[1]  for each in f],dtype=float)\n",
    "sample_num=len(Y)\n",
    "data_vector_dimension= X.shape[1]\n",
    "print(X.shape,Y.shape,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function shuffles input sequence accordingly.\n",
    "def shuffle_arrays(X_train, Y_train):\n",
    "    order= np.arange(Y_train.shape[0])\n",
    "    np.random.shuffle(order)\n",
    "    return (X_train[order], Y_train[order])\n",
    "    \n",
    "# sigmoid     \n",
    "def sigmoid( X):\n",
    "    result= np.clip(1e-8,1-(1e-8),1/(1.0+np.exp(-X)))\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "#Calc gradients for both weight and bias\n",
    "#input \n",
    "#X_train: batch_size *  data_vector_dimension\n",
    "def get_gradient(X_train, Y_train,Y_predict):\n",
    "    difference = Y_train.reshape(-1,1) - Y_predict\n",
    "#     print(difference.shape)\n",
    "#     print(X_train.shape)\n",
    "    w_gradient = -(X_train*difference).sum(0)\n",
    "#     print(X_train*difference)\n",
    "    b_gradient = -difference.sum()\n",
    "    \n",
    "    return w_gradient.reshape(-1,1),b_gradient\n",
    "\n",
    "#split X into X_train and X_test, Y accordingly.\n",
    "def split_XandY(X, Y, ratio):\n",
    "    train_size = int(len(Y)*ratio)\n",
    "    X_train = X[:train_size]\n",
    "    Y_train = Y[:train_size]\n",
    "    X_test = X[train_size:]\n",
    "    Y_test = Y[train_size:]\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "#This function normalizes all dimensions\n",
    "# X lines * 510?\n",
    "\n",
    "\n",
    "#######\n",
    "'''？？？？？？？？\n",
    "'''\n",
    "def normalize(X_train):\n",
    "    for i in range(X_train.shape[1]):\n",
    "        X_train[:,i] = (X_train[:,i]-np.mean(X_train[:,i]))/(np.std(X_train[:,i])+1e-8)\n",
    "    return X_train\n",
    "\n",
    "\n",
    "#cal predict rate:\n",
    "#def accuracy():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weight and bias\n",
    "weight=np.random.rand(data_vector_dimension,1)\n",
    "bias=np.random.rand(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define super-parameters for trainning\n",
    "batch_size = 8\n",
    "max_iter =10\n",
    "lr=0.2\n",
    "step=0\n",
    "ratio = 0.9\n",
    "batch_number = int(np.round(sample_num/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for training.\n",
    "X_train , Y_train, X_test, Y_test = split_XandY(X,Y,ratio)\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42895868,  1.00061455, -0.18298332, ...,  0.80594455,\n",
       "        -1.01452279,  1.01452279],\n",
       "       [ 1.20149032,  1.00061455, -0.18298332, ...,  0.80594455,\n",
       "        -1.01452279,  1.01452279],\n",
       "       [ 1.63627672, -0.99938579, -0.18298332, ..., -1.45784185,\n",
       "        -1.01452279,  1.01452279],\n",
       "       ...,\n",
       "       [ 0.65800732, -0.99938579, -0.18298332, ...,  0.80594455,\n",
       "        -1.01452279,  1.01452279],\n",
       "       [ 0.27756922,  1.00061455, -0.18298332, ...,  0.2835323 ,\n",
       "        -1.01452279,  1.01452279],\n",
       "       [ 0.16887262, -0.99938579, -0.18298332, ...,  0.80594455,\n",
       "         0.98568506, -0.98568506]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=np.zeros((data_vector_dimension,1),dtype=float)\n",
    "bias=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another kinds of statistics: 0.8767140961368328\n",
      "The 0th iter gives an acc of 0.8756092566045464\n",
      "Another kinds of statistics: 0.8879017988793866\n",
      "The 1th iter gives an acc of 0.8791521605570346\n",
      "Another kinds of statistics: 0.8898370687112946\n",
      "The 2th iter gives an acc of 0.8808109768584886\n",
      "Another kinds of statistics: 0.8909060749041581\n",
      "The 3th iter gives an acc of 0.8815277493344256\n",
      "Another kinds of statistics: 0.8916248894131524\n",
      "The 4th iter gives an acc of 0.8821421257423715\n",
      "Another kinds of statistics: 0.8921225302270717\n",
      "The 5th iter gives an acc of 0.8824493139463445\n",
      "Another kinds of statistics: 0.892417428487172\n",
      "The 6th iter gives an acc of 0.8829408150727012\n",
      "Another kinds of statistics: 0.8925095841934533\n",
      "The 7th iter gives an acc of 0.8828998566455049\n",
      "Another kinds of statistics: 0.8928782070185786\n",
      "The 8th iter gives an acc of 0.883125127995085\n",
      "Another kinds of statistics: 0.8931731052786789\n",
      "The 9th iter gives an acc of 0.8832480032766742\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_iter):\n",
    "    X_epoch, Y_epoch = X_train, Y_train\n",
    "    #X_epoch: xxx* 510\n",
    "    total = 0\n",
    "    wrong = 0\n",
    "    for batch_index in range(batch_number):\n",
    "        X_batch = X_epoch[batch_index*batch_size:(batch_index+1)*batch_size,:]\n",
    "        Y_batch = Y_epoch[batch_index*batch_size:(batch_index+1)*batch_size]\n",
    "        Y_predict = sigmoid(np.matmul(X_batch,weight)+bias)\n",
    "        w_gra, b_gra = get_gradient(X_batch,Y_batch,Y_predict)\n",
    "        Y_predict= np.round(Y_predict)\n",
    "        wrong+=np.abs(Y_predict.reshape(-1,1)-Y_batch.reshape(-1,1)).sum()\n",
    "        total+=batch_size\n",
    "        step+=1\n",
    "        weight-=lr*w_gra/np.sqrt(step)\n",
    "        bias-=lr*b_gra/np.sqrt(step)\n",
    "    Y_train_pred=np.round(sigmoid(np.dot(X_epoch,weight)+bias))\n",
    "    print(f'Another kinds of statistics: {1-wrong/total}')\n",
    "    print(f'The {epoch}th iter gives an acc of {1 - np.mean(np.abs(Y_train_pred.reshape(-1,1) - Y_epoch.reshape(-1,1)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
